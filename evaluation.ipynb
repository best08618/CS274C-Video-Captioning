{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "405e2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "### import shutil\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pickle, functools, operator\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import joblib\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import json\n",
    "import random\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, SimpleRNN , Concatenate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import mean_squared_error\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796f452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5da64663",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./training_data/AllVideoDescriptions.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ec033457",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test_split.txt','r') as f:\n",
    "    test_l = f.readlines()\n",
    "test_l = [l.replace('\\n','') for l in test_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "512ca452",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = {}\n",
    "for l in lines:\n",
    "    id = l.split(' ')[0]\n",
    "    script = ' '.join(l.split(' ')[1:])\n",
    "    if id in scripts:\n",
    "      scripts[id].append(script)\n",
    "    else:\n",
    "      scripts[id] = [script]\n",
    "scripts = {k:list(set(v)) for k,v in scripts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dfdd687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './model_att_general_2022-06-09 /'\n",
    "method ='beam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "36e55214",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{model_path}/test_output_{method}.txt','r') as f:\n",
    "    l = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3e78e105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinhwak/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jinhwak/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jinhwak/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# blues_all= []\n",
    "# meteors_all= []\n",
    "# bert =[]\n",
    "# result_all=[]\n",
    "# for gen in l:\n",
    "#     results= {}\n",
    "#     label_id = gen.split(',')[0]\n",
    "#     label = [i.replace('\\n','').split(' ') for i in scripts[label_id]]\n",
    "#     label_sentence= [[l.replace('\\n','') for l in scripts[label_id]]]\n",
    "#     gen_sentence =  [gen.split(',')[1].replace('\\n','')]\n",
    "#     gen = gen.split(',')[1].replace('\\n','').split(' ')\n",
    "#     gen = [g for g in gen if g!=' ' and g!='']\n",
    "#     blue =  sentence_bleu(\n",
    "#     label, gen,weights=[(1., 0), (0.5, 0.5), (0.333, 0.333, 0.334), (0.25, 0.25, 0.25, 0.25)])\n",
    "#     blues_all.append(blue)\n",
    "#     meteors= meteor_score(label, gen)\n",
    "#     meteors_all.append(meteors)\n",
    "# #    _,_,berts = score(gen_sentence, label_sentence, lang=\"en\", verbose=True)\n",
    "# #    bert.append(berts)\n",
    "#     results['video_id'] = label_id\n",
    "#     results['label'] = [\" \".join(l) for l in label]\n",
    "#     results['gen'] = \" \".join(gen)\n",
    "#     results['meteor'] = meteors\n",
    "#     results['bleu'] = blue\n",
    "#     results['bert_score'] = berts\n",
    "#     result_all.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a9368c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "././model_att_general_2022-06-09 //test_eval_beam.txt\n",
      "Final BLEU: [0.70267764 0.48326246 0.333825   0.15450715] METEOR: 0.5145667519365587\n"
     ]
    }
   ],
   "source": [
    "blues_all= []\n",
    "meteors_all= []\n",
    "with open(f'./{model_path}/test_eval_{method}.txt','w') as f:\n",
    "    print(f'./{model_path}/test_eval_{method}.txt')\n",
    "    for gen in l:\n",
    "        results= {}\n",
    "        label_id = gen.split(',')[0]\n",
    "        label = [i.replace('\\n','').split(' ') for i in scripts[label_id]]\n",
    "        gen = gen.split(',')[1].replace('\\n','').split(' ')\n",
    "        gen = [g for g in gen if g!=' ' and g!='']\n",
    "        blue =  sentence_bleu(\n",
    "        label, gen,weights=[(1., 0), (0.5, 0.5), (0.333, 0.333, 0.334), (0.25, 0.25, 0.25, 0.25)])\n",
    "        blues_all.append(blue)\n",
    "        meteors= nltk.translate.meteor_score.meteor_score(\n",
    "         label, gen)\n",
    "        meteors_all.append(meteors)\n",
    "        results['video_id'] = label_id\n",
    "        results['label'] = [\" \".join(l) for l in label]\n",
    "        results['gen'] = \" \".join(gen)\n",
    "        results['meteor'] = meteors\n",
    "        results['bleu'] = blue\n",
    "        f.write(json.dumps(results))\n",
    "        f.write(\"\\n\")\n",
    "    f.write(f\"Final BLEU: {np.mean(np.array(blues_all),axis=0)} METEOR: {np.mean(meteors_all)}\")\n",
    "    print(f\"Final BLEU: {np.mean(np.array(blues_all),axis=0)} METEOR: {np.mean(meteors_all)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2474d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
