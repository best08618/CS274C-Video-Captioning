{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc4f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import shutil\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pickle, functools, operator\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import joblib\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import json\n",
    "import random\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, SimpleRNN , Concatenate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import mean_squared_error\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab9d15d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config():\n",
    "    train_path = \"./training_data\"\n",
    "    test_path = \"./testing_data\"\n",
    "    batch_size = 160\n",
    "    learning_rate = 0.0007\n",
    "    epochs = 30\n",
    "    latent_dim = 512\n",
    "    num_encoder_tokens = 4096\n",
    "    num_decoder_tokens = 1500\n",
    "    time_steps_encoder = 80\n",
    "    max_probability = -1\n",
    "    save_model_path = 'model_final' \n",
    "    max_length = 30\n",
    "    search_type = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1852919",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220217d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ae8ca",
   "metadata": {},
   "source": [
    "## 02. Train & Test Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5da64663",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./training_data/AllVideoDescriptions.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24945f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train_split.txt','r') as f:\n",
    "    train_l = f.readlines()\n",
    "train_l = [l.replace('\\n','') for l in train_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c78d99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test_split.txt','r') as f:\n",
    "    test_l = f.readlines()\n",
    "test_l = [l.replace('\\n','') for l in test_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85852b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./val_split.txt','r') as f:\n",
    "    val_l = f.readlines()\n",
    "val_l = [l.replace('\\n','') for l in val_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "512ca452",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = {}\n",
    "for l in lines:\n",
    "    id = l.split(' ')[0]\n",
    "    script = ' '.join(l.split(' ')[1:])\n",
    "    if id in scripts:\n",
    "      scripts[id].append(script)\n",
    "    else:\n",
    "      scripts[id] = [script]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92982e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_list = []\n",
    "validation_list = []\n",
    "test_list = [] \n",
    "vocab_list = []\n",
    "\n",
    "for y in train_l:\n",
    "  for caption in scripts[y]:\n",
    "    caption = \"<bos> \" + caption + \" <eos>\"\n",
    "\n",
    "    training_list.append([caption, y])\n",
    "\n",
    "for y in val_l:\n",
    "  for caption in scripts[y]:\n",
    "    caption = \"<bos> \" + caption + \" <eos>\"\n",
    "\n",
    "    validation_list.append([caption, y])\n",
    "    \n",
    "for y in test_l:\n",
    "  for caption in scripts[y]:\n",
    "    caption = \"<bos> \" + caption + \" <eos>\"\n",
    "\n",
    "    test_list.append([caption, y])\n",
    "\n",
    "train_list = training_list + validation_list + test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16814fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = training_list + validation_list + test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a11f890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80827\n",
      "9463\n",
      "48774\n",
      "4290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1970"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_list))\n",
    "random.shuffle(training_list)\n",
    "random.shuffle(validation_list)\n",
    "random.shuffle(test_list)\n",
    "\n",
    "for train in training_list:\n",
    "    vocab_list.append(train[0])\n",
    "# Tokenizing the words\n",
    "tokenizer = Tokenizer(num_words=1500)\n",
    "tokenizer.fit_on_texts(vocab_list)\n",
    "print(len(tokenizer.word_index))\n",
    "x_data = {}\n",
    "TRAIN_FEATURE_DIR = os.path.join('training_data', 'features_dir')\n",
    "# Loading all the numpy arrays at once and saving them in a dictionary\n",
    "for filename in os.listdir(TRAIN_FEATURE_DIR):\n",
    "    f = np.load(os.path.join(TRAIN_FEATURE_DIR, filename))\n",
    "    x_data[filename[:-4]] = f\n",
    "print(len(training_list))\n",
    "print(len(validation_list))\n",
    "len(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d5c6b8",
   "metadata": {},
   "source": [
    "## 03. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51967968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom data generator because we cannot load so many files at once\n",
    "def load_datatest(train_path, epochs=100, x_data=x_data, tokenizer=tokenizer, num_decoder_tokens=1500,training_list=training_list, batch_size=32, maxlen=11):\n",
    "    encoder_input_data = []\n",
    "    decoder_input_data = []\n",
    "    decoder_target_data = []\n",
    "    videoId = []\n",
    "    videoSeq = []\n",
    "    # separating the videoId and the video captions\n",
    "    for idx, cap in enumerate(training_list):\n",
    "        caption = cap[0]\n",
    "        videoId.append(cap[1])\n",
    "        videoSeq.append(caption)\n",
    "    # converting the captions to tokens and padding them to equal sizes\n",
    "    train_sequences = tokenizer.texts_to_sequences(videoSeq)\n",
    "    train_sequences = np.array(train_sequences)\n",
    "    train_sequences = pad_sequences(train_sequences, padding='post',truncating='post', maxlen=maxlen)\n",
    "    max_seq_length = train_sequences.shape[1]\n",
    "    filesize = len(train_sequences)\n",
    "    vCount = 0\n",
    "    n = 0\n",
    "    for i in range(epochs):\n",
    "      for idx in  range(0,filesize):\n",
    "        n += 1\n",
    "        try:\n",
    "          encoder_input_data.append(x_data[videoId[idx]])\n",
    "        except:\n",
    "          continue\n",
    "        y = to_categorical(train_sequences[idx], num_decoder_tokens)\n",
    "        decoder_input_data.append(y[:-1])\n",
    "        decoder_target_data.append(y[1:])\n",
    "        if n == batch_size:\n",
    "          encoder_input = np.array(encoder_input_data)\n",
    "          decoder_input = np.array(decoder_input_data)\n",
    "          decoder_target = np.array(decoder_target_data)\n",
    "          encoder_input_data = []\n",
    "          decoder_input_data = []\n",
    "          decoder_target_data = []\n",
    "          n = 0\n",
    "          yield ([encoder_input, decoder_input, decoder_target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9deffd54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# writing the train and validation generator\n",
    "train = load_datatest(train_path='training_data',batch_size=config.batch_size, training_list=training_list, x_data=x_data, epochs=300)\n",
    "valid = load_datatest(train_path='training_data',batch_size=config.batch_size, training_list=validation_list, x_data=x_data, epochs=300)\n",
    "test = load_datatest(train_path='test_data',batch_size=config.batch_size, training_list=test_list, x_data=x_data,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39da7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, hidden_dim,time_steps_encoder,num_encoder_tokens):\n",
    "        super(Encoder, self).__init__()\n",
    "        # Define the RNN layer, LSTM\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = tf.keras.layers.LSTM( \n",
    "            hidden_dim, return_sequences=True, return_state=True, input_shape=(time_steps_encoder,num_encoder_tokens))\n",
    "\n",
    "    def call(self, input_sequence, states):\n",
    "        # Call the LSTM unit\n",
    "        output, state_h, state_c = self.lstm(input_sequence, initial_state=states)\n",
    "\n",
    "        return output, state_h, state_c\n",
    "\n",
    "    def init_states(self, batch_size):\n",
    "        # Return a all 0s initial states\n",
    "        return (tf.zeros([batch_size, self.hidden_dim]),\n",
    "                tf.zeros([batch_size, self.hidden_dim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78b183df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttention(tf.keras.Model):\n",
    "    def __init__(self, rnn_size, attention_func):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        self.attention_func = attention_func\n",
    "\n",
    "        if attention_func not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(\n",
    "                'Attention score must be either dot, general or concat.')\n",
    "\n",
    "        if attention_func == 'general':\n",
    "            # General score function\n",
    "            self.wa = tf.keras.layers.Dense(rnn_size)\n",
    "        elif attention_func == 'concat':\n",
    "            # Concat score function\n",
    "            self.wa = tf.keras.layers.Dense(rnn_size, activation='tanh')\n",
    "            self.va = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, decoder_output, encoder_output):\n",
    "        if self.attention_func == 'dot':\n",
    "            # Dot score function: decoder_output (dot) encoder_output\n",
    "            # decoder_output has shape: (batch_size, 1, rnn_size)\n",
    "            # encoder_output has shape: (batch_size, max_len, rnn_size)\n",
    "            # => score has shape: (batch_size, 1, max_len)\n",
    "            score = tf.matmul(decoder_output, encoder_output, transpose_b=True) # (batch_size, 1, max_len)\n",
    "        elif self.attention_func == 'general':\n",
    "            # General score function: decoder_output (dot) (Wa (dot) encoder_output)\n",
    "            # decoder_output has shape: (batch_size, 1, rnn_size)\n",
    "            # encoder_output has shape: (batch_size, max_len, rnn_size)\n",
    "            # => score has shape: (batch_size, 1, max_len)\n",
    "            score = tf.matmul(decoder_output, self.wa(\n",
    "                encoder_output), transpose_b=True) #(batch_size, 1, max_len)\n",
    "        elif self.attention_func == 'concat':\n",
    "            # Concat score function: va (dot) tanh(Wa (dot) concat(decoder_output + encoder_output))\n",
    "            # Decoder output must be broadcasted to encoder output's shape first\n",
    "            decoder_output = tf.tile(\n",
    "                decoder_output, [1, encoder_output.shape[1], 1]) #shape (batch size, max len,hidden_dim)\n",
    "\n",
    "            # Concat => Wa => va\n",
    "            # (batch_size, max_len, 2 * rnn_size) => (batch_size, max_len, rnn_size) => (batch_size, max_len, 1)\n",
    "            score = self.va(\n",
    "                self.wa(tf.concat((decoder_output, encoder_output), axis=-1))) # (batch_size, max len, 1)\n",
    "\n",
    "            # Transpose score vector to have the same shape as other two above\n",
    "            # (batch_size, max_len, 1) => (batch_size, 1, max_len)\n",
    "            score = tf.transpose(score, [0, 2, 1]) #(batch_size, 1, max_len)\n",
    "\n",
    "        # alignment a_t = softmax(score)\n",
    "        alignment = tf.keras.activations.softmax(score, axis=-1) #(batch_size, 1, max_len)\n",
    "        \n",
    "        # context vector c_t is the weighted average sum of encoder output\n",
    "        context = tf.matmul(alignment, encoder_output) # (batch_size, 1, hidden_dim)\n",
    "\n",
    "        return context, alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "516c97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size,hidden_dim,time_steps_encoder,num_encoder_tokens,attention_func):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attention = LuongAttention(hidden_dim, attention_func)\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            hidden_dim, return_sequences=True, return_state=True,input_shape=(None,num_encoder_tokens))\n",
    "        self.wc = tf.keras.layers.Dense(hidden_dim, activation='tanh')\n",
    "        self.ws = tf.keras.layers.Dense(vocab_size,activation='softmax')\n",
    "        \n",
    "    def call(self, input_sequence, state,encoder_output):\n",
    "        # Call the LSTM unit\n",
    "        lstm_out, state_h, state_c = self.lstm(input_sequence, state)\n",
    "        context , alignment = self.attention(lstm_out,encoder_output)\n",
    "        lstm_out = tf.concat(\n",
    "        [tf.squeeze(context, 1), tf.squeeze(lstm_out, 1)], 1)\n",
    "        lstm_out = self.wc(lstm_out)\n",
    "        logits = self.ws(lstm_out)\n",
    "\n",
    "\n",
    "        return logits, state_h, state_c, alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0911be43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 11:03:28.903513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:28.904388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:28.912480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:28.913048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:28.913591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:28.914098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:28.914959: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-09 11:03:29.193607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:29.194121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:29.194632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:29.195088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:29.195579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:29.196030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:29.876487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:29.877035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:29.877542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:29.878025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:29.878522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:29.878984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7409 MB memory:  -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:0d:00.0, compute capability: 7.5\n",
      "2022-06-09 11:03:29.879335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 11:03:29.879810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9645 MB memory:  -> device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:0e:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "#Set the length of the input and output vocabulary\n",
    "time_steps_encoder=80\n",
    "num_encoder_tokens=4096\n",
    "latent_dim=512\n",
    "time_steps_decoder=30\n",
    "num_decoder_tokens=1500\n",
    "batch_size=160\n",
    "HIDDEN_DIM =  latent_dim\n",
    "\n",
    "#Create the encoder\n",
    "encoder = Encoder(HIDDEN_DIM,time_steps_encoder,num_encoder_tokens)\n",
    "# Get the initial states\n",
    "initial_state = encoder.init_states(1)\n",
    "\n",
    "# Create the decoder\n",
    "decoder = Decoder(num_decoder_tokens,HIDDEN_DIM,time_steps_decoder,num_encoder_tokens,'general')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74001858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(targets, logits):\n",
    "    crossentropy = tf.keras.losses.CategoricalCrossentropy()\n",
    "    # Mask padding values, they do not have to compute for loss\n",
    "    mask = tf.math.logical_not(tf.math.equal(tf.argmax(targets,-1), 0))\n",
    "    mask = tf.cast(mask, dtype=tf.int64)\n",
    "    # Calculate the loss value\n",
    "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    # y_pred shape is batch_size, seq length, vocab size\n",
    "    # y_true shape is batch_size, seq length\n",
    "    pred_values = K.cast(K.argmax(y_pred, axis=-1), dtype='int32')\n",
    "    y_true = K.cast(K.argmax(y_true, axis=-1), dtype='int32')\n",
    "    correct = K.cast(K.equal(y_true, pred_values), dtype='float32')\n",
    "\n",
    "    # 0 is padding, don't include those\n",
    "    mask = K.cast(K.greater(y_true, 0), dtype='float32')\n",
    "    n_correct = K.sum(mask * correct)\n",
    "    n_total = K.sum(mask)\n",
    "    return n_correct / n_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18e99b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the @tf.function decorator to take advance of static graph computation\n",
    "@tf.function\n",
    "def train_step_att(input_seq, target_seq_in, target_seq_out, en_initial_states, optimizer):\n",
    "    ''' A training step, train a batch of the data and return the loss value reached\n",
    "        Input:\n",
    "        - input_seq: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
    "            the input sequence\n",
    "        - target_seq_out: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
    "            the target seq, our target sequence\n",
    "        - target_seq_in: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
    "            the input sequence to the decoder, we use Teacher Forcing\n",
    "        - en_initial_states: tuple of arrays of shape [batch_size, hidden_dim].\n",
    "            the initial state of the encoder\n",
    "        - optimizer: a tf.keras.optimizers.\n",
    "        Output:\n",
    "        - loss: loss value\n",
    "        \n",
    "    '''\n",
    "    loss = 0.\n",
    "    acc = 0.\n",
    "    logits = None\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        en_outputs = encoder(input_seq, en_initial_states)\n",
    "        en_states = en_outputs[1:]\n",
    "        de_state_h, de_state_c = en_states\n",
    "\n",
    "        # We need to create a loop to iterate through the target sequences\n",
    "        for i in range(target_seq_out.shape[1]):\n",
    "            # Input to the decoder must have shape of (batch_size, length)\n",
    "            # so we need to expand one dimension\n",
    "            decoder_in = tf.expand_dims(target_seq_in[:, i], 1)\n",
    "            logit, de_state_h, de_state_c, _ = decoder(\n",
    "                decoder_in, (de_state_h, de_state_c), en_outputs[0])\n",
    "\n",
    "            # The loss is now accumulated through the whole batch\n",
    "            loss += loss_func(target_seq_out[:, i], logit)\n",
    "            # Store the logits to calculate the accuracy\n",
    "            logit = K.expand_dims(logit, axis=1)\n",
    "            if logits is None:\n",
    "                logits = logit\n",
    "            else:\n",
    "                logits = K.concatenate((logits,logit), axis=1)\n",
    "        # Calculate the accuracy for the batch data   \n",
    "        acc = accuracy_fn(target_seq_out, logits)\n",
    "    # Update the parameters and the optimizer\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return loss / target_seq_out.shape[1] ,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e52d4050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Create the main train function\n",
    "def main_train(encoder, decoder, dataset, n_epochs, batch_size, optimizer, checkpoint, checkpoint_prefix):\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for e in range(n_epochs):\n",
    "        # Get the initial time\n",
    "        start = time.time()\n",
    "        # Get the initial state for the encoder\n",
    "        en_initial_states = encoder.init_states(batch_size)\n",
    "        # For every batch data\n",
    "        batch = 0\n",
    "        for (input_seq, target_seq_in, target_seq_out) in dataset:\n",
    "            # Train and get the loss value \n",
    "            batch += 1 \n",
    "            loss,acc = train_step_att(input_seq, target_seq_in, target_seq_out, en_initial_states, optimizer)\n",
    "            if batch % 100 == 0:\n",
    "                # Store the loss and accuracy values\n",
    "                losses.append(loss)\n",
    "                accuracies.append(acc)\n",
    "                print('Epoch {} Batch {} Loss {:.4f} Acc{:.4f}'.format(e + 1, batch, loss.numpy(),acc.numpy()))\n",
    "                \n",
    "        # saving (checkpoint) the model every 2 epochs\n",
    "        if (e + 1) % 2 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "        print('Time taken for 1 epoch {:.4f} sec\\n'.format(time.time() - start))\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efaf65ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2440552/2721968490.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_sequences = np.array(train_sequences)\n",
      "2022-06-09 11:03:38.126478: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"GeForce RTX 2080 Ti\" frequency: 1650 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 7769620480 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-09 11:03:38.126595: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"GeForce RTX 2080 Ti\" frequency: 1650 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 7769620480 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-09 11:03:38.126678: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"GeForce RTX 2080 Ti\" frequency: 1650 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 7769620480 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-09 11:03:38.126886: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"GeForce RTX 2080 Ti\" frequency: 1650 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 7769620480 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-09 11:03:38.127122: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"GeForce RTX 2080 Ti\" frequency: 1650 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 7769620480 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-09 11:03:38.127332: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"GeForce RTX 2080 Ti\" frequency: 1650 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 7769620480 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-09 11:03:38.127591: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"GeForce RTX 2080 Ti\" frequency: 1650 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 7769620480 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-09 11:03:38.127833: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"GeForce RTX 2080 Ti\" frequency: 1650 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 7769620480 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-09 11:03:38.128067: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"GeForce RTX 2080 Ti\" frequency: 1650 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 7769620480 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-09 11:03:38.128213: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"GeForce RTX 2080 Ti\" frequency: 1650 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 7769620480 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2022-06-09 11:03:39.727710: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 100 Loss 2.5367 Acc0.3948\n",
      "Epoch 1 Batch 200 Loss 2.1949 Acc0.4247\n",
      "Epoch 1 Batch 300 Loss 1.9830 Acc0.4655\n",
      "Epoch 1 Batch 400 Loss 1.6430 Acc0.5318\n",
      "Epoch 1 Batch 500 Loss 1.5328 Acc0.5363\n",
      "Epoch 1 Batch 600 Loss 1.4654 Acc0.5701\n",
      "Epoch 1 Batch 700 Loss 1.4827 Acc0.5559\n",
      "Epoch 1 Batch 800 Loss 1.3361 Acc0.5690\n",
      "Epoch 1 Batch 900 Loss 1.2609 Acc0.6185\n",
      "Epoch 1 Batch 1000 Loss 1.3951 Acc0.5880\n",
      "Epoch 1 Batch 1100 Loss 1.3104 Acc0.5834\n",
      "Epoch 1 Batch 1200 Loss 1.1884 Acc0.6061\n",
      "Epoch 1 Batch 1300 Loss 1.1101 Acc0.6393\n",
      "Epoch 1 Batch 1400 Loss 1.1736 Acc0.6053\n",
      "Epoch 1 Batch 1500 Loss 1.0639 Acc0.6503\n",
      "Epoch 1 Batch 1600 Loss 1.1868 Acc0.6142\n",
      "Epoch 1 Batch 1700 Loss 1.1750 Acc0.6133\n",
      "Epoch 1 Batch 1800 Loss 1.1203 Acc0.6118\n",
      "Epoch 1 Batch 1900 Loss 1.3115 Acc0.5742\n",
      "Epoch 1 Batch 2000 Loss 1.1153 Acc0.6292\n",
      "Epoch 1 Batch 2100 Loss 1.0169 Acc0.6336\n",
      "Epoch 1 Batch 2200 Loss 1.0494 Acc0.6221\n",
      "Epoch 1 Batch 2300 Loss 1.0712 Acc0.6192\n",
      "Epoch 1 Batch 2400 Loss 1.1009 Acc0.6342\n",
      "Epoch 1 Batch 2500 Loss 1.1749 Acc0.6190\n",
      "Epoch 1 Batch 2600 Loss 0.9964 Acc0.6471\n",
      "Epoch 1 Batch 2700 Loss 1.1073 Acc0.6125\n",
      "Epoch 1 Batch 2800 Loss 1.0668 Acc0.6306\n",
      "Epoch 1 Batch 2900 Loss 1.0423 Acc0.6314\n",
      "Epoch 1 Batch 3000 Loss 0.9652 Acc0.6613\n",
      "Epoch 1 Batch 3100 Loss 0.9244 Acc0.6678\n",
      "Epoch 1 Batch 3200 Loss 0.8382 Acc0.6912\n",
      "Epoch 1 Batch 3300 Loss 0.9826 Acc0.6707\n",
      "Epoch 1 Batch 3400 Loss 0.9401 Acc0.6690\n",
      "Epoch 1 Batch 3500 Loss 0.9373 Acc0.6486\n",
      "Epoch 1 Batch 3600 Loss 0.8687 Acc0.6708\n",
      "Epoch 1 Batch 3700 Loss 0.9062 Acc0.6480\n",
      "Epoch 1 Batch 3800 Loss 0.8877 Acc0.6806\n",
      "Epoch 1 Batch 3900 Loss 0.9053 Acc0.6699\n",
      "Epoch 1 Batch 4000 Loss 0.8575 Acc0.6799\n",
      "Epoch 1 Batch 4100 Loss 0.9497 Acc0.6613\n",
      "Epoch 1 Batch 4200 Loss 0.8545 Acc0.6837\n",
      "Epoch 1 Batch 4300 Loss 0.7662 Acc0.7001\n",
      "Epoch 1 Batch 4400 Loss 0.8458 Acc0.6931\n",
      "Epoch 1 Batch 4500 Loss 0.8282 Acc0.6866\n",
      "Epoch 1 Batch 4600 Loss 0.7915 Acc0.7028\n",
      "Epoch 1 Batch 4700 Loss 0.7780 Acc0.7160\n",
      "Epoch 1 Batch 4800 Loss 0.8336 Acc0.6858\n",
      "Epoch 1 Batch 4900 Loss 0.7654 Acc0.7064\n",
      "Epoch 1 Batch 5000 Loss 0.8205 Acc0.6951\n",
      "Epoch 1 Batch 5100 Loss 0.7614 Acc0.6991\n",
      "Epoch 1 Batch 5200 Loss 0.7794 Acc0.6969\n",
      "Epoch 1 Batch 5300 Loss 0.7542 Acc0.7129\n",
      "Epoch 1 Batch 5400 Loss 0.7345 Acc0.7238\n",
      "Epoch 1 Batch 5500 Loss 0.7568 Acc0.7117\n",
      "Epoch 1 Batch 5600 Loss 0.7258 Acc0.7228\n",
      "Epoch 1 Batch 5700 Loss 0.7234 Acc0.7144\n",
      "Epoch 1 Batch 5800 Loss 0.7197 Acc0.7312\n",
      "Epoch 1 Batch 5900 Loss 0.6723 Acc0.7479\n",
      "Epoch 1 Batch 6000 Loss 0.6922 Acc0.7342\n",
      "Epoch 1 Batch 6100 Loss 0.6786 Acc0.7365\n",
      "Epoch 1 Batch 6200 Loss 0.6718 Acc0.7394\n",
      "Epoch 1 Batch 6300 Loss 0.7001 Acc0.7305\n",
      "Epoch 1 Batch 6400 Loss 0.7195 Acc0.7154\n",
      "Epoch 1 Batch 6500 Loss 0.6601 Acc0.7345\n",
      "Epoch 1 Batch 6600 Loss 0.6569 Acc0.7460\n",
      "Epoch 1 Batch 6700 Loss 0.6164 Acc0.7442\n",
      "Epoch 1 Batch 6800 Loss 0.6644 Acc0.7411\n",
      "Epoch 1 Batch 6900 Loss 0.6492 Acc0.7465\n",
      "Epoch 1 Batch 7000 Loss 0.6257 Acc0.7659\n",
      "Epoch 1 Batch 7100 Loss 0.6490 Acc0.7509\n",
      "Epoch 1 Batch 7200 Loss 0.6206 Acc0.7524\n",
      "Epoch 1 Batch 7300 Loss 0.6507 Acc0.7555\n",
      "Epoch 1 Batch 7400 Loss 0.6319 Acc0.7637\n",
      "Epoch 1 Batch 7500 Loss 0.6079 Acc0.7614\n",
      "Epoch 1 Batch 7600 Loss 0.5854 Acc0.7877\n",
      "Epoch 1 Batch 7700 Loss 0.5683 Acc0.7677\n",
      "Epoch 1 Batch 7800 Loss 0.5905 Acc0.7461\n",
      "Epoch 1 Batch 7900 Loss 0.5847 Acc0.7703\n",
      "Epoch 1 Batch 8000 Loss 0.5608 Acc0.7719\n",
      "Epoch 1 Batch 8100 Loss 0.5760 Acc0.7661\n",
      "Epoch 1 Batch 8200 Loss 0.5657 Acc0.7682\n",
      "Epoch 1 Batch 8300 Loss 0.6097 Acc0.7899\n",
      "Epoch 1 Batch 8400 Loss 0.5636 Acc0.7693\n",
      "Epoch 1 Batch 8500 Loss 0.5327 Acc0.7732\n",
      "Epoch 1 Batch 8600 Loss 0.5596 Acc0.7743\n",
      "Epoch 1 Batch 8700 Loss 0.5053 Acc0.7914\n",
      "Epoch 1 Batch 8800 Loss 0.4979 Acc0.7863\n",
      "Epoch 1 Batch 8900 Loss 0.5402 Acc0.7826\n",
      "Epoch 1 Batch 9000 Loss 0.5541 Acc0.7852\n",
      "Epoch 1 Batch 9100 Loss 0.5287 Acc0.7933\n",
      "Epoch 1 Batch 9200 Loss 0.5466 Acc0.7880\n",
      "Epoch 1 Batch 9300 Loss 0.5125 Acc0.7857\n",
      "Epoch 1 Batch 9400 Loss 0.5281 Acc0.7867\n",
      "Epoch 1 Batch 9500 Loss 0.5339 Acc0.7889\n",
      "Epoch 1 Batch 9600 Loss 0.5130 Acc0.7863\n",
      "Epoch 1 Batch 9700 Loss 0.5039 Acc0.7981\n",
      "Epoch 1 Batch 9800 Loss 0.5410 Acc0.7798\n",
      "Epoch 1 Batch 9900 Loss 0.5349 Acc0.7888\n",
      "Epoch 1 Batch 10000 Loss 0.5491 Acc0.7702\n",
      "Epoch 1 Batch 10100 Loss 0.5059 Acc0.7953\n",
      "Epoch 1 Batch 10200 Loss 0.5408 Acc0.7735\n",
      "Epoch 1 Batch 10300 Loss 0.5129 Acc0.7950\n",
      "Epoch 1 Batch 10400 Loss 0.4760 Acc0.7907\n",
      "Epoch 1 Batch 10500 Loss 0.5063 Acc0.7861\n",
      "Epoch 1 Batch 10600 Loss 0.4892 Acc0.8046\n",
      "Epoch 1 Batch 10700 Loss 0.4970 Acc0.7901\n",
      "Epoch 1 Batch 10800 Loss 0.4978 Acc0.7906\n",
      "Epoch 1 Batch 10900 Loss 0.5094 Acc0.8096\n",
      "Epoch 1 Batch 11000 Loss 0.4482 Acc0.8234\n",
      "Epoch 1 Batch 11100 Loss 0.4863 Acc0.7916\n",
      "Epoch 1 Batch 11200 Loss 0.4741 Acc0.8025\n",
      "Epoch 1 Batch 11300 Loss 0.4597 Acc0.8174\n",
      "Epoch 1 Batch 11400 Loss 0.4644 Acc0.8074\n",
      "Epoch 1 Batch 11500 Loss 0.4819 Acc0.8047\n",
      "Epoch 1 Batch 11600 Loss 0.4689 Acc0.8058\n",
      "Epoch 1 Batch 11700 Loss 0.5103 Acc0.7820\n",
      "Epoch 1 Batch 11800 Loss 0.4990 Acc0.8096\n",
      "Epoch 1 Batch 11900 Loss 0.4601 Acc0.8177\n",
      "Epoch 1 Batch 12000 Loss 0.4797 Acc0.7968\n",
      "Epoch 1 Batch 12100 Loss 0.4328 Acc0.8076\n",
      "Epoch 1 Batch 12200 Loss 0.4189 Acc0.8193\n",
      "Epoch 1 Batch 12300 Loss 0.4560 Acc0.7988\n",
      "Epoch 1 Batch 12400 Loss 0.4630 Acc0.8109\n",
      "Epoch 1 Batch 12500 Loss 0.4699 Acc0.7919\n",
      "Epoch 1 Batch 12600 Loss 0.4349 Acc0.8187\n",
      "Epoch 1 Batch 12700 Loss 0.4323 Acc0.8318\n",
      "Epoch 1 Batch 12800 Loss 0.4547 Acc0.8031\n",
      "Epoch 1 Batch 12900 Loss 0.4746 Acc0.7938\n",
      "Epoch 1 Batch 13000 Loss 0.4482 Acc0.8242\n",
      "Epoch 1 Batch 13100 Loss 0.4240 Acc0.8260\n",
      "Epoch 1 Batch 13200 Loss 0.4514 Acc0.8096\n",
      "Epoch 1 Batch 13300 Loss 0.4757 Acc0.8111\n",
      "Epoch 1 Batch 13400 Loss 0.4065 Acc0.8307\n",
      "Epoch 1 Batch 13500 Loss 0.4130 Acc0.8184\n",
      "Epoch 1 Batch 13600 Loss 0.4686 Acc0.8000\n",
      "Epoch 1 Batch 13700 Loss 0.4339 Acc0.8271\n",
      "Epoch 1 Batch 13800 Loss 0.4374 Acc0.8145\n",
      "Epoch 1 Batch 13900 Loss 0.4747 Acc0.7938\n",
      "Epoch 1 Batch 14000 Loss 0.4171 Acc0.8375\n",
      "Epoch 1 Batch 14100 Loss 0.4430 Acc0.8085\n",
      "Epoch 1 Batch 14200 Loss 0.4203 Acc0.8206\n",
      "Epoch 1 Batch 14300 Loss 0.4223 Acc0.8332\n",
      "Epoch 1 Batch 14400 Loss 0.4607 Acc0.8177\n",
      "Epoch 1 Batch 14500 Loss 0.4318 Acc0.8129\n",
      "Epoch 1 Batch 14600 Loss 0.4282 Acc0.8241\n",
      "Epoch 1 Batch 14700 Loss 0.3856 Acc0.8339\n",
      "Epoch 1 Batch 14800 Loss 0.4662 Acc0.8108\n",
      "Epoch 1 Batch 14900 Loss 0.4109 Acc0.8199\n",
      "Epoch 1 Batch 15000 Loss 0.4402 Acc0.8187\n",
      "Epoch 1 Batch 15100 Loss 0.4452 Acc0.8226\n",
      "Epoch 1 Batch 15200 Loss 0.3851 Acc0.8259\n",
      "Epoch 1 Batch 15300 Loss 0.4229 Acc0.8080\n",
      "Epoch 1 Batch 15400 Loss 0.4065 Acc0.8223\n",
      "Epoch 1 Batch 15500 Loss 0.4108 Acc0.8189\n",
      "Epoch 1 Batch 15600 Loss 0.4170 Acc0.8329\n",
      "Epoch 1 Batch 15700 Loss 0.4113 Acc0.8228\n",
      "Epoch 1 Batch 15800 Loss 0.4054 Acc0.8326\n",
      "Epoch 1 Batch 15900 Loss 0.4057 Acc0.8195\n",
      "Epoch 1 Batch 16000 Loss 0.4152 Acc0.8181\n",
      "Epoch 1 Batch 16100 Loss 0.4249 Acc0.8071\n",
      "Epoch 1 Batch 16200 Loss 0.4071 Acc0.8124\n",
      "Epoch 1 Batch 16300 Loss 0.3797 Acc0.8448\n",
      "Epoch 1 Batch 16400 Loss 0.4199 Acc0.8239\n",
      "Epoch 1 Batch 16500 Loss 0.3909 Acc0.8400\n",
      "Epoch 1 Batch 16600 Loss 0.3931 Acc0.8141\n",
      "Epoch 1 Batch 16700 Loss 0.3600 Acc0.8442\n",
      "Epoch 1 Batch 16800 Loss 0.3915 Acc0.8284\n",
      "Epoch 1 Batch 16900 Loss 0.3749 Acc0.8357\n",
      "Epoch 1 Batch 17000 Loss 0.4078 Acc0.8157\n",
      "Epoch 1 Batch 17100 Loss 0.4256 Acc0.8232\n",
      "Epoch 1 Batch 17200 Loss 0.3951 Acc0.8289\n",
      "Epoch 1 Batch 17300 Loss 0.3867 Acc0.8243\n",
      "Epoch 1 Batch 17400 Loss 0.4044 Acc0.8356\n",
      "Epoch 1 Batch 17500 Loss 0.3807 Acc0.8323\n",
      "Epoch 1 Batch 17600 Loss 0.3746 Acc0.8298\n",
      "Epoch 1 Batch 17700 Loss 0.4098 Acc0.8197\n",
      "Epoch 1 Batch 17800 Loss 0.4001 Acc0.8231\n",
      "Epoch 1 Batch 17900 Loss 0.3694 Acc0.8227\n",
      "Epoch 1 Batch 18000 Loss 0.3959 Acc0.8296\n",
      "Epoch 1 Batch 18100 Loss 0.4005 Acc0.8279\n",
      "Epoch 1 Batch 18200 Loss 0.3735 Acc0.8349\n",
      "Epoch 1 Batch 18300 Loss 0.3844 Acc0.8313\n",
      "Epoch 1 Batch 18400 Loss 0.3918 Acc0.8335\n",
      "Epoch 1 Batch 18500 Loss 0.3955 Acc0.8319\n",
      "Epoch 1 Batch 18600 Loss 0.3996 Acc0.8285\n",
      "Epoch 1 Batch 18700 Loss 0.3973 Acc0.8406\n",
      "Epoch 1 Batch 18800 Loss 0.4242 Acc0.8096\n",
      "Epoch 1 Batch 18900 Loss 0.3987 Acc0.8322\n",
      "Epoch 1 Batch 19000 Loss 0.3857 Acc0.8224\n",
      "Epoch 1 Batch 19100 Loss 0.4030 Acc0.8287\n",
      "Epoch 1 Batch 19200 Loss 0.3794 Acc0.8427\n",
      "Epoch 1 Batch 19300 Loss 0.3858 Acc0.8265\n",
      "Epoch 1 Batch 19400 Loss 0.4157 Acc0.8206\n",
      "Epoch 1 Batch 19500 Loss 0.3796 Acc0.8542\n",
      "Epoch 1 Batch 19600 Loss 0.3878 Acc0.8293\n",
      "Epoch 1 Batch 19700 Loss 0.3934 Acc0.8194\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m checkpoint_prefix \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mCheckpoint(optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m      7\u001b[0m                                  encoder\u001b[38;5;241m=\u001b[39mencoder,\n\u001b[1;32m      8\u001b[0m                                  decoder\u001b[38;5;241m=\u001b[39mdecoder)\n\u001b[0;32m---> 10\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mmain_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mmain_train\u001b[0;34m(encoder, decoder, dataset, n_epochs, batch_size, optimizer, checkpoint, checkpoint_prefix)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (input_seq, target_seq_in, target_seq_out) \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Train and get the loss value \u001b[39;00m\n\u001b[1;32m     16\u001b[0m     batch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[0;32m---> 17\u001b[0m     loss,acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step_att\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_seq_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_seq_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43men_initial_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;66;03m# Store the loss and accuracy values\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         losses\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2955\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2952\u001b[0m \u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m-> 2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mgraph_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3244\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3220\u001b[0m \u001b[38;5;124;03m\"\"\"Gets a function for these inputs, defining it if necessary.\u001b[39;00m\n\u001b[1;32m   3221\u001b[0m \n\u001b[1;32m   3222\u001b[0m \u001b[38;5;124;03m`args` and `kwargs` can be None if this `Function` was created with an\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;124;03m    shape relaxation retracing.\u001b[39;00m\n\u001b[1;32m   3241\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3243\u001b[0m   args, kwargs, flat_args, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m-> 3244\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_function_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3246\u001b[0m   flat_args, filtered_flat_args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2766\u001b[0m, in \u001b[0;36mFunctionSpec.canonicalize_function_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2763\u001b[0m       kwargs\u001b[38;5;241m.\u001b[39msetdefault(kwarg, default)\n\u001b[1;32m   2765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2766\u001b[0m   inputs, flat_inputs, filtered_flat_inputs \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_numpy_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2767\u001b[0m   kwargs, flat_kwargs, filtered_flat_kwargs \u001b[38;5;241m=\u001b[39m _convert_numpy_inputs(kwargs)\n\u001b[1;32m   2768\u001b[0m   flat_inputs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m flat_kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2806\u001b[0m, in \u001b[0;36m_convert_numpy_inputs\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   2804\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output of __array__ must be an np.ndarray, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2805\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(a)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2806\u001b[0m flat_inputs[index] \u001b[38;5;241m=\u001b[39m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2807\u001b[0m filtered_flat_inputs\u001b[38;5;241m.\u001b[39mappend(flat_inputs[index])\n\u001b[1;32m   2808\u001b[0m need_packing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(clipnorm=5.0,learning_rate=0.001)\n",
    "# Create a checkpoint object to save the model\n",
    "checkpoint_dir = './training_ckpt_seq2seq_att_general'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "\n",
    "losses = main_train(encoder, decoder, train, config.epochs, batch_size, optimizer, checkpoint, checkpoint_prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1695e698",
   "metadata": {},
   "source": [
    "# Save Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d2c3288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model path is : model_att_general_2022-06-09 \n"
     ]
    }
   ],
   "source": [
    "x = datetime.datetime.now()\n",
    "save_model_path = 'model_att_general_' + str(x)[:11]\n",
    "print(f\"Save model path is : {save_model_path}\")\n",
    "\n",
    "if not os.path.exists(save_model_path):\n",
    "    os.makedirs(save_model_path)\n",
    "    \n",
    "encoder.save_weights(os.path.join(save_model_path, 'encoder.h5'))\n",
    "\n",
    "decoder.save_weights(os.path.join(save_model_path, 'decoder.h5'))\n",
    "\n",
    "with open(os.path.join(save_model_path,'tokenizer'+ str(num_decoder_tokens) ),'wb') as file:\n",
    "    joblib.dump(tokenizer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ff831",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fb8fc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2265836/2721968490.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_sequences = np.array(train_sequences)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.         0.         1.819204   ... 0.40537566 0.         0.        ]\n",
      "  [0.         0.         1.8118318  ... 1.0780952  0.         0.        ]\n",
      "  [0.         0.         1.6541446  ... 1.4459221  0.         0.        ]\n",
      "  ...\n",
      "  [0.19641858 0.         2.2582536  ... 2.3994093  0.         0.8078662 ]\n",
      "  [0.         0.         2.3914156  ... 2.899564   0.         0.5467725 ]\n",
      "  [0.         0.         2.6686835  ... 2.4830456  0.         0.9339806 ]]\n",
      "\n",
      " [[0.         1.6346111  0.9470917  ... 0.         0.88411826 0.        ]\n",
      "  [0.         1.418968   1.2187812  ... 0.         1.0428629  0.        ]\n",
      "  [0.         1.4772139  1.2610791  ... 0.         0.8922333  0.        ]\n",
      "  ...\n",
      "  [1.0113212  0.         2.7485347  ... 0.         0.         0.21230459]\n",
      "  [0.1960218  0.         2.6216874  ... 0.         0.         0.        ]\n",
      "  [1.0169246  0.         3.0582728  ... 0.         0.1516946  0.        ]]\n",
      "\n",
      " [[1.3638706  3.9225347  0.         ... 0.         0.         0.46920353]\n",
      "  [0.9628048  3.103214   0.         ... 0.         0.         0.        ]\n",
      "  [0.6108959  2.8842971  0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         1.578725   0.         ... 0.         0.         0.        ]\n",
      "  [0.06602502 2.440331   0.         ... 0.         0.         0.        ]\n",
      "  [0.25604576 2.5087564  0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.5529832  ... 0.7321483  0.         0.        ]\n",
      "  [0.         0.         0.         ... 2.1165729  0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.24414572 0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         1.1756483  0.        ]\n",
      "  [0.         0.         0.5596772  ... 0.         0.53584695 0.        ]\n",
      "  [0.         0.         0.3832671  ... 0.         1.3564873  0.        ]]\n",
      "\n",
      " [[2.38304    0.         0.         ... 0.08161467 0.         1.1634316 ]\n",
      "  [2.663505   0.         0.         ... 0.14151782 0.         0.9638031 ]\n",
      "  [2.0519676  0.         0.         ... 0.17287487 0.         0.2709511 ]\n",
      "  ...\n",
      "  [1.0387781  0.         0.         ... 1.4043641  0.         0.8562786 ]\n",
      "  [0.94286716 0.         0.         ... 1.2030213  0.         0.7021331 ]\n",
      "  [0.83525    0.         0.         ... 1.1591709  0.         0.73622966]]] [[[0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]] [[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 14:27:56.478665: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    }
   ],
   "source": [
    "for ei,di, do in train:\n",
    "    print(ei,di,do)\n",
    "    break\n",
    "\n",
    "save_model_path = './model_att_concat_2022-05-25 /'\n",
    "encoder = Encoder(HIDDEN_DIM,time_steps_encoder,num_encoder_tokens)\n",
    "output =encoder(ei,encoder.init_states(batch_size))\n",
    "encoder.load_weights(os.path.join(save_model_path, 'encoder.h5'))\n",
    "\n",
    "de_input = np.zeros((320, 1, 1500))\n",
    "de_idx = tokenizer.word_index['bos']\n",
    "de_state_h, de_state_c = output[1:]\n",
    "decoder = Decoder(HIDDEN_DIM,time_steps_encoder,num_encoder_tokens)\n",
    "decoder(de_input, (de_state_h, de_state_c), output[0])\n",
    "decoder.load_weights(os.path.join(save_model_path, 'decoder.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9a46b",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae6d6aa",
   "metadata": {},
   "source": [
    "## 05. Inference Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "276b826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to perform inference on all test files and save as test_output.txt\n",
    "class Video2Text(object):\n",
    "    ''' Initialize the parameters for the model '''\n",
    "    def __init__(self,encoder,decoder,tokenizer,save_model_path):\n",
    "        self.latent_dim = 512\n",
    "        self.num_encoder_tokens = 4096\n",
    "        self.num_decoder_tokens = 1500\n",
    "        self.time_steps_encoder = 80\n",
    "        self.time_steps_decoder = None\n",
    "        self.preload = True\n",
    "        self.preload_data_path = 'preload_data'\n",
    "        self.max_probability = -1\n",
    "\n",
    "        # processed data\n",
    "        self.encoder_input_data = []\n",
    "        self.decoder_input_data = []\n",
    "        self.decoder_target_data = []\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        # models\n",
    "        self.encoder_model = None\n",
    "        self.decoder_model = None\n",
    "        self.inf_encoder_model = None\n",
    "        self.inf_decoder_model = None\n",
    "        self.save_model_path = save_model_path\n",
    "        self.test_path = 'testing_data'\n",
    "        self.inf_encoder_model = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    \n",
    "    def decode_sequence2bs(self, input_seq):\n",
    "        en_initial_states = self.inf_encoder_model.init_states(1)\n",
    "        output, state_h,state_c = self.inf_encoder_model(input_seq,en_initial_states)\n",
    "        target_seq = np.zeros((1, 1, self.num_decoder_tokens))\n",
    "        target_seq[0, 0, self.tokenizer.word_index['bos']] = 1\n",
    "        self.beam_search(target_seq, [state_h,state_c],[],[],0,output)\n",
    "        return decode_seq\n",
    "\n",
    "    def beam_search(self, target_seq, states_value, prob,  path, lens,en_output):\n",
    "        global decode_seq\n",
    "        node = 2\n",
    "        output_tokens, de_state_h, de_state_c, alignment = self.decoder(\n",
    "                    target_seq, states_value, en_output)\n",
    "        output_tokens = tf.reshape(output_tokens,self.num_decoder_tokens)#.reshape((self.num_decoder_tokens))\n",
    "\n",
    "        sampled_token_index = tf.argsort(output_tokens,-1).numpy()[-10:][::-1]       \n",
    "        states_value = [de_state_h, de_state_c]\n",
    "        for i in range(node):\n",
    "            if sampled_token_index[i] == 0:\n",
    "                sampled_char = ''\n",
    "            else:\n",
    "                sampled_char = list(self.tokenizer.word_index.keys())[list(self.tokenizer.word_index.values()).index(sampled_token_index[i])]\n",
    "            if(sampled_char != 'eos' and lens <= config.max_length):\n",
    "                p = output_tokens[sampled_token_index[i]]\n",
    "                if(sampled_char == ''):\n",
    "                    p = 1\n",
    "                prob_new = list(prob)\n",
    "                prob_new.append(p)\n",
    "                path_new = list(path)\n",
    "                path_new.append(sampled_char)\n",
    "                target_seq = np.zeros((1, 1, self.num_decoder_tokens))\n",
    "                target_seq[0, 0, sampled_token_index[i]] = 1.\n",
    "                self.beam_search(target_seq, states_value, prob_new, path_new, lens+1,en_output)\n",
    "            else:\n",
    "                p = output_tokens[sampled_token_index[i]]\n",
    "                prob_new = list(prob)\n",
    "                prob_new.append(p)\n",
    "                p = functools.reduce(operator.mul, prob_new, 1)\n",
    "                if(p > self.max_probability):\n",
    "                    decode_seq = path\n",
    "                    self.max_probability = p\n",
    "\n",
    "    def decoded_sentence_tuning(self, decoded_sentence):\n",
    "        decode_str = []\n",
    "        filter_string = ['bos', 'eos']\n",
    "        unigram = {}\n",
    "        last_string = \"\"\n",
    "        for idx2, c in enumerate(decoded_sentence):\n",
    "            if c in unigram:\n",
    "                unigram[c] += 1\n",
    "            else:\n",
    "                unigram[c] = 1\n",
    "            if(last_string == c and idx2 > 0):\n",
    "                continue\n",
    "            if c in filter_string:\n",
    "                continue\n",
    "            if len(c) > 0:\n",
    "                decode_str.append(c)\n",
    "            if idx2 > 0:\n",
    "                last_string = c\n",
    "        return decode_str\n",
    "\n",
    "    def get_test_data(self, path):\n",
    "        X_test = []\n",
    "        X_test_filename = []\n",
    "#         with open (os.path.join(path, 'testing_id.txt')) as testing_file:\n",
    "#             lines = testing_file.readlines()\n",
    "#             for filename in lines:\n",
    "#                 filename = filename.strip()\n",
    "#                 f = np.load(os.path.join(path , 'feat', filename + '.npy'))\n",
    "#                 X_test.append(f)\n",
    "#                 X_test_filename.append(filename[:-4])\n",
    "#             X_test = np.array(X_test)\n",
    "        for filename in test_l:\n",
    "            try:\n",
    "                f = np.load(os.path.join(path , 'features_dir', filename + '.npy'))\n",
    "            except: \n",
    "                print('not exsits')\n",
    "                continue\n",
    "            X_test.append(f)\n",
    "            X_test_filename.append(filename)\n",
    "        return X_test, X_test_filename\n",
    "\n",
    "    def test(self):\n",
    "        X_test, X_test_filename = self.get_test_data(os.path.join(config.train_path)) \n",
    "        self.X_test , self.X_test_filename = X_test, X_test_filename\n",
    "        # generate inference test outputs\n",
    "        with open(os.path.join(self.save_model_path, 'test_output_topk.txt'), 'w') as file:\n",
    "            for idx, x in enumerate(X_test): \n",
    "                file.write(X_test_filename[idx]+',')\n",
    "                decoded_sentence = self.decode_sequence2bs(x.reshape(-1, 80, 4096))\n",
    "                decode_str = self.decoded_sentence_tuning(decoded_sentence)\n",
    "                for d in decode_str:\n",
    "                    file.write(d + ' ')\n",
    "                file.write('\\n')\n",
    "                # re-init max prob\n",
    "                self.max_probability = -1\n",
    "                \n",
    "    def index_to_word(self):\n",
    "        # inverts word tokenizer\n",
    "        index_to_word = {value: key for key, value in self.tokenizer.word_index.items()}\n",
    "        return index_to_word\n",
    "                \n",
    "    def greedy_search(self, f):\n",
    "        \"\"\"\n",
    "                :param f: the loaded numpy array after creating videos to frames and extracting features\n",
    "                :return: the final sentence which has been predicted greedily\n",
    "                \"\"\"\n",
    "        inv_map = self.index_to_word()\n",
    "        encoder_output = self.inf_encoder_model.predict(f.reshape(-1, 80, 4096))\n",
    "        target_seq = np.zeros((1, 1, 1500))\n",
    "        sentence = ''\n",
    "        target_seq[0, 0, self.tokenizer.word_index['bos']] = 1\n",
    "        for i in range(config.max_length):\n",
    "            output_tokens = self.inf_decoder_model.predict([target_seq, encoder_output])\n",
    "            output_tokens = output_tokens.reshape(self.num_decoder_tokens)\n",
    "            y_hat = np.argmax(output_tokens)\n",
    "            if y_hat == 0:\n",
    "                continue\n",
    "            if inv_map[y_hat] is None:\n",
    "                break\n",
    "            else:\n",
    "                sentence = sentence + inv_map[y_hat] + ' '\n",
    "                target_seq = np.zeros((1, 1, 1500))\n",
    "                target_seq[0, 0, y_hat] = 1\n",
    "        return ' '.join(sentence.split()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85edbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Video2Text(encoder,decoder,tokenizer,save_model_path)\n",
    "c.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18809941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video",
   "language": "python",
   "name": "video"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
