{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc4f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pickle, functools, operator\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import joblib\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import json\n",
    "import random\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, SimpleRNN , Concatenate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import mean_squared_error\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab9d15d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config():\n",
    "    train_path = \"./training_data\"\n",
    "    test_path = \"./testing_data\"\n",
    "    batch_size = 160\n",
    "    learning_rate = 0.0007\n",
    "    epochs = 150\n",
    "    latent_dim = 512\n",
    "    num_encoder_tokens = 4096\n",
    "    num_decoder_tokens = 1500\n",
    "    time_steps_encoder = 80\n",
    "    max_probability = -1\n",
    "    save_model_path = 'model_final'\n",
    "    validation_split = 0.15\n",
    "    max_length = 10\n",
    "    search_type = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1852919",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3014d2cb",
   "metadata": {},
   "source": [
    "## 01. Video Feature Extraction from VGG model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85a923db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frames(video):\n",
    "    path = os.path.join(config.train_path, 'temporary_images')\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "    video_path = os.path.join(config.train_path, 'video', video)\n",
    "    count = 0\n",
    "    image_list = []\n",
    "    # Path to video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret is False:\n",
    "            break\n",
    "        cv2.imwrite(os.path.join(config.train_path, 'temporary_images', 'frame%d.jpg' % count), frame)\n",
    "        image_list.append(os.path.join(config.train_path, 'temporary_images', 'frame%d.jpg' % count))\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return image_list\n",
    "\n",
    "\n",
    "def model_cnn_load():\n",
    "    model = VGG16(weights=\"imagenet\", include_top=True, input_shape=(224, 224, 3))\n",
    "    out = model.layers[-2].output\n",
    "    model_final = Model(inputs=model.input, outputs=out)\n",
    "    return model_final\n",
    "\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    return img\n",
    "\n",
    "\n",
    "def extract_features(video, model):\n",
    "    \"\"\"\n",
    "    :param video: The video whose frames are to be extracted to convert into a numpy array\n",
    "    :param model: the pretrained vgg16 model\n",
    "    :return: numpy array of size 4096x80\n",
    "    \"\"\"\n",
    "    video_id = video.split(\".\")[0]\n",
    "    print(video_id)\n",
    "    print(f'Processing video {video}')\n",
    "\n",
    "    image_list = video_to_frames(video)\n",
    "    samples = np.round(np.linspace(\n",
    "        0, len(image_list) - 1, 80))\n",
    "    image_list = [image_list[int(sample)] for sample in samples]\n",
    "    images = np.zeros((len(image_list), 224, 224, 3))\n",
    "    for i in range(len(image_list)):\n",
    "        img = load_image(image_list[i])\n",
    "        images[i] = img\n",
    "    images = np.array(images)\n",
    "    fc_feats = model.predict(images, batch_size=128)\n",
    "    img_feats = np.array(fc_feats)\n",
    "    # cleanup\n",
    "    shutil.rmtree(os.path.join(config.train_path, 'temporary_images'))\n",
    "    return img_feats\n",
    "\n",
    "\n",
    "def extract_feats_pretrained_cnn():\n",
    "    \"\"\"\n",
    "    saves the numpy features from all the videos\n",
    "    \"\"\"\n",
    "    model = model_cnn_load()\n",
    "    print('Model loaded')\n",
    "\n",
    "    if not os.path.isdir(os.path.join(config.train_path, 'features_dir')):\n",
    "        os.mkdir(os.path.join(config.train_path, 'features_dir'))\n",
    "\n",
    "    video_list = os.listdir(os.path.join(config.train_path, 'video'))\n",
    "    for video in video_list:\n",
    "\n",
    "        outfile = os.path.join(config.train_path, 'features_dir', video.split(\".\")[0] + '.npy')\n",
    "        img_feats = extract_features(video, model)\n",
    "        np.save(outfile, img_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab1a7be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 14:48:13.743087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:13.743682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:13.749222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:13.749786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:13.750318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:13.750835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:13.751780: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-03 14:48:14.057588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:14.058122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:14.058613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:14.059089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:14.059564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:14.060045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:14.651129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:14.651686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:14.652179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:14.652662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:14.653143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:14.653625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9628 MB memory:  -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:0d:00.0, compute capability: 7.5\n",
      "2022-06-03 14:48:14.653954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-03 14:48:14.654416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9645 MB memory:  -> device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:0e:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mextract_feats_pretrained_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mextract_feats_pretrained_cnn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_feats_pretrained_cnn\u001b[39m():\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    saves the numpy features from all the videos\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_cnn_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel loaded\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(config\u001b[38;5;241m.\u001b[39mtrain_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures_dir\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mmodel_cnn_load\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_cnn_load\u001b[39m():\n\u001b[0;32m---> 25\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mVGG16\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     out \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39moutput\n\u001b[1;32m     27\u001b[0m     model_final \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39minput, outputs\u001b[38;5;241m=\u001b[39mout)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/applications/vgg16.py:212\u001b[0m, in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    211\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m include_top:\n\u001b[0;32m--> 212\u001b[0m     weights_path \u001b[38;5;241m=\u001b[39m \u001b[43mdata_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvgg16_weights_tf_dim_ordering_tf_kernels.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mWEIGHTS_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_subdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m64373286793e3c8b2b4e3219cbf3544b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     weights_path \u001b[38;5;241m=\u001b[39m data_utils\u001b[38;5;241m.\u001b[39mget_file(\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    220\u001b[0m         WEIGHTS_PATH_NO_TOP,\n\u001b[1;32m    221\u001b[0m         cache_subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    222\u001b[0m         file_hash\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6d6bbae143d832006294945121d1f1fc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/data_utils.py:248\u001b[0m, in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fpath):\n\u001b[1;32m    246\u001b[0m   \u001b[38;5;66;03m# File found; verify integrity if a hash was provided.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m file_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mvalidate_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_hash\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhash_algorithm\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    249\u001b[0m       io_utils\u001b[38;5;241m.\u001b[39mprint_msg(\n\u001b[1;32m    250\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA local file was found, but it seems to be \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    251\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincomplete or outdated because the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhash_algorithm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    252\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile hash does not match the original value of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    253\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mso we will re-download the data.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    254\u001b[0m       download \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/data_utils.py:362\u001b[0m, in \u001b[0;36mvalidate_file\u001b[0;34m(fpath, file_hash, algorithm, chunk_size)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m\"\"\"Validates a file against a sha256 or md5 hash.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    Whether the file is valid\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    360\u001b[0m hasher \u001b[38;5;241m=\u001b[39m _resolve_hasher(algorithm, file_hash)\n\u001b[0;32m--> 362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[43m_hash_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m(file_hash):\n\u001b[1;32m    363\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/data_utils.py:341\u001b[0m, in \u001b[0;36m_hash_file\u001b[0;34m(fpath, algorithm, chunk_size)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fpath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fpath_file:\n\u001b[1;32m    340\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: fpath_file\u001b[38;5;241m.\u001b[39mread(chunk_size), \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 341\u001b[0m     \u001b[43mhasher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hasher\u001b[38;5;241m.\u001b[39mhexdigest()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "extract_feats_pretrained_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1ae5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
